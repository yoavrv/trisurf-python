{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3757fb13-080d-47b2-951a-7382e042f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"Script: make fxw plot of distribution from FW summaries.\n",
    "\n",
    "Created on Sun May 23 2021\n",
    "\n",
    "@author: yoav\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import concurrent.futures as cf\n",
    "from itertools import product\n",
    "import glob as glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import re as re\n",
    "from matplotlib import cm\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f29716f-afbd-40a6-a4c9-54a92648d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lam(keyable, key):\n",
    "    if key in keyable:\n",
    "        return keyable[key]\n",
    "    key2 = key[:3] + key[4] + key[3] + key[5:]\n",
    "    if key2 in keyable:\n",
    "        return keyable[key2]\n",
    "    return keyable[key] # raise KeyError\n",
    "\n",
    "def data_from_files(metadata):\n",
    "    \"\"\"Get data from files.\n",
    "    \n",
    "    Extract data from the files in the fw subfolder of metadata[\"folder\"]\n",
    "    \"\"\"\n",
    "\n",
    "    datas = [[{} for w in metadata[\"file_ws\"]] for f in metadata[\"file_fs\"]]\n",
    "    metas = [[{**metadata} for w in metadata[\"file_ws\"]] for f in metadata[\"file_fs\"]]\n",
    "    for i,f in enumerate(metadata[\"file_fs\"]):\n",
    "        for j,w in enumerate(metadata[\"file_ws\"]):\n",
    "            meta = metas[i][j]\n",
    "            meta[\"file_fs\"] = f\n",
    "            meta[\"file_ws\"] = w\n",
    "            if metadata[\"file_r\"] is not None:\n",
    "                r = metadata[\"file_r\"]\n",
    "                meta[\"folder\"] = metadata[\"folder\"] + f\"/x000{f+8*w}_f{f:02}w{w:02}c00r00\"\n",
    "            else:\n",
    "                meta[\"folder\"] = metadata[\"folder\"] + f\"/f{f}w{w}\"\n",
    "\n",
    "    arg_generator = (\n",
    "                     (datas[i[0]][i[1]], metas[i[0]][i[1]])\n",
    "                     for i in \n",
    "                     product( range(len(metadata[\"file_fs\"])), range(len(metadata[\"file_ws\"])) )\n",
    "                    )\n",
    "\n",
    "    with cf.ThreadPoolExecutor() as ex:\n",
    "        ex.map(tuple_args_ij_files, arg_generator)\n",
    "    #for args in arg_generator:\n",
    "    #    tuple_args_ij_files(args)\n",
    "\n",
    "\n",
    "    return datas #and update metadata\n",
    "\n",
    "\n",
    "def tuple_args_ij_files(arg_tuple):\n",
    "    \"\"\"Wrap single file function for map.\"\"\"\n",
    "    dist_from_ij(*arg_tuple)\n",
    "\n",
    "\n",
    "def dist_from_ij(data, meta):\n",
    "    \"\"\"Get cluster distribution of a single folder.\"\"\"\n",
    "    #  start\n",
    "    \n",
    "    data[\"success\"] = True\n",
    "    try:\n",
    "        # get simulation parameters\n",
    "        timestep_vtu = glob.glob(meta[\"folder\"] + \"/timestep*.vtu\")\n",
    "        if not timestep_vtu:\n",
    "            raise FileNotFoundError(\"no timesteps were found\")\n",
    "        # parse vtu as xml file\n",
    "        tree = ET.parse(timestep_vtu[-1])\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # directly extract the one tape, get f,w\n",
    "        tape = root.findall('tape')[0].text\n",
    "        f_regex = re.compile(r\"\\n(F=[\\d.]+)\")\n",
    "        w_regex = re.compile(r\"\\n(w=[\\d.]+)\")\n",
    "        true_f = re.findall(f_regex, tape)[0]\n",
    "        true_w = re.findall(w_regex, tape)[0]\n",
    "        data[\"f\"] = float(true_f[2:])\n",
    "        data[\"w\"] = float(true_w[2:])\n",
    "\n",
    "        \n",
    "        ##number of vertex\n",
    "        #n_vertices = root.findall('trisurf')[0].attrib[\"nvtx\"]\n",
    "        type_nodes = root.findall('.//*[@Name=\"type\"]')\n",
    "        if type_nodes:\n",
    "            t_node = root.findall('.//*[@Name=\"spontaneous_curvature\"]')[0]\n",
    "            num_active = sum(int(x)&2==2 for x in t_node.text.strip().split())\n",
    "        else:\n",
    "            c_node = root.findall('.//*[@Name=\"spontaneous_curvature\"]')[0]\n",
    "            num_active = sum(float(x)>0 for x in c_node.text.strip().split())\n",
    "\n",
    "\n",
    "    \n",
    "        # now for the data\n",
    "        pystat_names = (\"No\", \"Volume\", \"Area\", \"lambda1\",\n",
    "                        \"lambda2\", \"lambda3\", \"Nbw/Nb\", \"hbar\",\n",
    "                        \"mean_cluster_size\", \"std_cluster_size\",\n",
    "                        \"line_length\", \"asphericity\", \"gyration_radius\",\n",
    "                        \"acylindricity\", \"lamdba1\",\n",
    "                        \"lamdba2\", \"lamdba3\"\n",
    "                       )\n",
    "        stat_names = (\"Epoch\",\"OuterLoop\", \"VertexMoveSucessRate\",\n",
    "                  \"BondFlipSuccessRate\"\n",
    "                     )\n",
    "        calculated_hist_names = (\"cluster_size_dist\")\n",
    "\n",
    "    \n",
    "        if meta[\"data_type\"] in pystat_names:\n",
    "            # get a main_statistics or pystatisics \n",
    "            # (regular statistics: output of trisurf)\n",
    "            stat_csv = glob.glob(meta[\"folder\"]+'/[mp]*.csv')[0]\n",
    "            df = pd.read_csv(stat_csv)\n",
    "            data[\"x\"] = df[\"No\"][meta[\"slice\"]]\n",
    "        \n",
    "        elif meta[\"data_type\"] in stat_names:\n",
    "            # get stuff that only exists in statistics.csv\n",
    "            df = pd.read_csv(meta[\"folder\"]+'/statistics.csv')\n",
    "            data[\"x\"] = df[\"OuterLoop\"][meta[\"slice\"]]\n",
    "    \n",
    "        elif meta[\"data_type\"] in calculated_hist_names:\n",
    "            file_list=glob.glob(meta[\"folder\"]+'/hist*.csv')\n",
    "            hist = np.zeros([num_active,2], dtype=int)\n",
    "            hist[:,0] = np.arange(1,num_active+1)\n",
    "            # couldn't find any way to make pandas do this\n",
    "            for file in file_list[meta[\"slice\"]]:\n",
    "                a = np.genfromtxt(file,\n",
    "                                  skip_header=1,\n",
    "                                  delimiter=',',\n",
    "                                  dtype=int)\n",
    "                hist[a[...,0]-1,1] += a[...,1]\n",
    "            df = pd.DataFrame({\"cluster_size\":hist[...,0], \"number_of_clusters\":hist[...,1]/float(sum(hist[...,1]))})\n",
    "            data[\"x\"] = df[\"cluster_size\"]\n",
    "        \n",
    "\n",
    "        # use options\n",
    "        if meta[\"data_type\"]=='cluster_size_dist':\n",
    "            data[\"y\"] = df[\"number_of_clusters\"]\n",
    "        \n",
    "        elif meta[\"data_type\"]=='asphericity':\n",
    "            data[\"y\"] = (get_lam(df,'lambda3')[meta[\"slice\"]]\n",
    "                        - 0.5*get_lam(df,'lambda2')[meta[\"slice\"]]\n",
    "                        - 0.5*get_lam(df,'lambda1')[meta[\"slice\"]])\n",
    "        \n",
    "        elif meta[\"data_type\"]=='gyration_radius':\n",
    "            data[\"y\"] = (get_lam(df,'lambda1')[meta[\"slice\"]]\n",
    "                        + get_lam(df,'lambda2')[meta[\"slice\"]]\n",
    "                        + get_lam(df,'lambda3')[meta[\"slice\"]])\n",
    "        \n",
    "        elif meta[\"data_type\"]=='acylindricity':\n",
    "            data[\"y\"] = (get_lam(df,'lambda2')[meta[\"slice\"]]\n",
    "                        - get_lam(df,'lambda1')[meta[\"slice\"]])\n",
    "    \n",
    "        elif meta[\"data_type\"] in {\"lambda1\", \"lambda2\", \"lambda3\", \"lamdba1\", \"lamdba2\", \"lamdba3\"}:\n",
    "            data[\"y\"] = get_lam(df,meta[\"data_type\"])[meta[\"slice\"]]\n",
    "        else:\n",
    "\n",
    "            data[\"y\"] = df[meta[\"data_type\"]][meta[\"slice\"]]\n",
    "    \n",
    "        if meta[\"data_type\"] in calculated_hist_names:\n",
    "            f = data[\"y\"]/(data[\"y\"].sum())\n",
    "            if meta[\"do_mean\"]:\n",
    "                data[\"mean\"] = (f*data[\"x\"]).sum()\n",
    "            if meta[\"do_std\"]:\n",
    "                data[\"std\"] = (f*(data[\"x\"]-(f*data[\"x\"]).sum())**2).sum()**0.5\n",
    "            if meta[\"do_skew\"]:\n",
    "                data[\"skew\"] = (f*( (data[\"x\"]-(f*data[\"x\"]).sum())**3 / ((f*(data[\"x\"]-(f*data[\"x\"]).sum())**2).sum())**1.5 )).sum()\n",
    "            if meta[\"do_kurtosis\"]:\n",
    "                data[\"kurtosis\"] = (f*( (data[\"x\"]-(f*data[\"x\"]).sum())**4 / ((f*(data[\"x\"]-(f*data[\"x\"]).sum())**2).sum())**2 )).sum()\n",
    "        else:\n",
    "            if meta[\"do_mean\"]:\n",
    "                data[\"mean\"] = data[\"y\"].mean()\n",
    "            if meta[\"do_std\"]:\n",
    "                data[\"std\"] = data[\"y\"].std()\n",
    "            if meta[\"do_skew\"]:\n",
    "                data[\"skew\"] = data[\"y\"].skew()\n",
    "            if meta[\"do_kurtosis\"]:\n",
    "                data[\"kurtosis\"] = data[\"y\"].kurtosis() # please?\n",
    "    except FileNotFoundError as e:\n",
    "        data[\"y\"] = np.nan\n",
    "        data[\"x\"] = np.nan\n",
    "        data[\"success\"] = False\n",
    "        ## try and get a value for f,w\n",
    "         # get simulation parameters\n",
    "        timestep_vtu = glob.glob(meta[\"folder\"] + \"/*.vtu\")\n",
    "        if timestep_vtu: # found an alternative vtu\n",
    "            tree = ET.parse(timestep_vtu[-1])\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # directly extract the one tape, get f,w\n",
    "            tape = root.findall('tape')[0].text\n",
    "            f_regex = re.compile(r\"\\n(F=[\\d.]+)\")\n",
    "            w_regex = re.compile(r\"\\n(w=[\\d.]+)\")\n",
    "            true_f = re.findall(f_regex, tape)[0]\n",
    "            true_w = re.findall(w_regex, tape)[0]\n",
    "            data[\"f\"] = float(true_f[2:])\n",
    "            data[\"w\"] = float(true_w[2:])\n",
    "        else: # try simulation_parameter\n",
    "            with open(meta[\"folder\"]+\"/simulation_parameter\",\"r\") as file:\n",
    "                text = file.read()\n",
    "                f_regex = re.compile(r\"(f=[\\d.]+)\")\n",
    "                w_regex = re.compile(r\"(w=[\\d.]+)\")\n",
    "                true_f = re.findall(f_regex, text)[0]\n",
    "                true_w = re.findall(w_regex, text)[0]\n",
    "                data[\"f\"] = float(true_f[2:])\n",
    "                data[\"w\"] = float(true_w[2:])\n",
    "                \n",
    "                \n",
    "            \n",
    "    except Exception as e:\n",
    "        data[\"e\"] = e\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b724ddf5-c9d7-45ed-bb16-f496a6eeaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fxw(datas, metadata):\n",
    "    \"\"\"Plot fxw graphs.\n",
    "\n",
    "    plot fxw graphs in a square, in a matrixlike form\n",
    "    from a fxw list of datas\n",
    "    \"\"\"\n",
    "    def dist_label_mean(x):\n",
    "        return fr'$\\mu = {x:.2f}$'\n",
    "\n",
    "    def dist_label_std(x):\n",
    "        return fr'$\\sigma = {x:.2f}$'\n",
    "    \n",
    "    def filter_dict(given_dict, default_dict, irrelevant_keys_set):\n",
    "        \"filter a given dectionary to only include keys in the relevant_keys set, then add defaults\"\n",
    "        relevant_given = {key: value for key, value in given_dict.items() if key not in irrelevant_keys_set}\n",
    "        for key in default_dict.keys():\n",
    "            if key not in relevant_given:\n",
    "                relevant_given[key]=default_dict[key]\n",
    "        return relevant_given\n",
    "            \n",
    "    \n",
    "    #def axis_range(min_val,max_val):\n",
    "    #    mid = (max_val + min_val) /2\n",
    "    #    dif = (max_val - min_val) /2\n",
    "    #    return mid-1.05*dif, mid+1.05*dif\n",
    "\n",
    "    f_range, w_range = list(range(len(datas))), list((range(len(datas[0]))))\n",
    "    \n",
    "    # ranges: matrix ij goes down with i, right with j\n",
    "    # xy goes right with x and up with y- x=j, y=reverse(i)\n",
    "    if metadata[\"order\"] == \"ij=fw\":\n",
    "        i_range, j_range = f_range, w_range\n",
    "        ij_datas = [ [datas[i][j] for j in j_range] for i in i_range ]\n",
    "        x_param, y_param = \"w\", \"f\"\n",
    "        do_mat = True\n",
    "    elif metadata[\"order\"] == \"ij=wf\":\n",
    "        i_range, j_range = w_range, f_range\n",
    "        ij_datas = [ [datas[j][i] for j in j_range] for i in i_range ]\n",
    "        x_param, y_param = \"f\", \"w\"\n",
    "        do_mat = True\n",
    "    elif metadata[\"order\"] == \"xy=fw\":\n",
    "        j_range, i_range = f_range, w_range\n",
    "        ij_datas = [ [datas[j][i] for j in j_range] for i in reversed(i_range) ]\n",
    "        x_param, y_param = \"f\", \"w\"\n",
    "        do_mat = False\n",
    "    elif metadata[\"order\"] == \"xy=wf\":\n",
    "        i_range, j_range = f_range, w_range\n",
    "        ij_datas = [ [datas[i][j] for j in j_range] for i in reversed(i_range) ]\n",
    "        x_param, y_param = \"w\", \"f\"\n",
    "        do_mat = False\n",
    "\n",
    "    \n",
    "    if metadata[\"plot_type\"] == \"pcolor\":\n",
    "        #pcolor is a single mesh\n",
    "        if \"axe_scale\" in metadata:\n",
    "            plt.xscale(metadata[\"axe_scale\"][0])\n",
    "            plt.yscale(metadata[\"axe_scale\"][1])\n",
    "        # data key:\n",
    "        if metadata[\"do_mean\"]:\n",
    "            key=\"mean\"\n",
    "        elif metadata[\"do_std\"]:\n",
    "            key=\"std\"\n",
    "        elif metadata[\"do_skew\"]:\n",
    "            key=\"skew\"\n",
    "        elif metadata[\"do_kurtosis\"]:\n",
    "            key=\"kurtosis\"\n",
    "        else:\n",
    "            key=\"y\"\n",
    "\n",
    "        for datastrip in ij_datas:\n",
    "            for data in datastrip:\n",
    "                if not data[\"success\"]:\n",
    "                    data[key] = np.nan\n",
    "        # not sure if pcolor follows matrix or xy coordinates\n",
    "        if metadata[\"data_transform\"]:\n",
    "            mesh = [[metadata[\"data_transform\"](data[key]) for data in datastrip ] for datastrip in ij_datas]\n",
    "        else:\n",
    "            mesh = [[data[key] for data in datastrip ] for datastrip in ij_datas]\n",
    "        X = [[data[x_param] for data in datastrip ] for datastrip in ij_datas]\n",
    "        Y = [[data[y_param] for data in datastrip ] for datastrip in ij_datas]\n",
    "\n",
    "        \n",
    "        \n",
    "        default_mesh_params={\"shading\":\"nearest\"}\n",
    "        irrelevant_mesh_keys={\"bottom\", \"align\",\"color\"}\n",
    "        plt.pcolormesh( X, Y, mesh,\n",
    "                    **filter_dict(metadata[\"plot_kwargs\"], \n",
    "                                       default_mesh_params,\n",
    "                                       irrelevant_mesh_keys)\n",
    "                    )\n",
    "        plt.xlabel(x_param)\n",
    "        plt.ylabel(y_param)\n",
    " \n",
    "        if metadata[\"do_title\"]:\n",
    "            plt.title(f' FW plot: {metadata[\"data_type\"]}')\n",
    "            \n",
    "        plt.xticks(X[0])\n",
    "        plt.yticks([a[0] for a in Y])\n",
    "        if do_mat:\n",
    "            bottom, top = plt.ylim()\n",
    "            plt.ylim(top, bottom)\n",
    "        plt.colorbar()\n",
    "        return True\n",
    "        \n",
    "\n",
    "\n",
    "    # make big figure\n",
    "    plt.rcParams['figure.figsize'] = [10, 6.8] # [10,6.8] # [20,18] 4_lines: worked with [40, 6.8]\n",
    "    if metadata[\"fig_size\"]:\n",
    "        plt.rcParams['figure.figsize'] = metadata[\"fig_size\"]\n",
    "    if \"axe_share\" in metadata:\n",
    "        fig, axes = plt.subplots(nrows=len(i_range), ncols=len(j_range), sharex=metadata[\"axe_share\"][0], sharey=metadata[\"axe_share\"][1], num=metadata[\"data_type\"])\n",
    "    else:\n",
    "        fig, axes = plt.subplots(nrows=len(i_range), ncols=len(j_range), num=metadata[\"data_type\"])\n",
    "\n",
    "\n",
    "    for i in i_range:\n",
    "        for j in j_range:\n",
    "            try:\n",
    "                axe = axes[i, j]\n",
    "            except TypeError:\n",
    "                axe=axes\n",
    "            data = ij_datas[i][j]\n",
    "            if data[\"success\"] == False:\n",
    "                pass\n",
    "            else:\n",
    "            \n",
    "                if \"axe_scale\" in metadata:\n",
    "                    axe.set_xscale(metadata[\"axe_scale\"][0])\n",
    "                    axe.set_yscale(metadata[\"axe_scale\"][1])\n",
    "    \n",
    "                if metadata[\"plot_type\"] == \"plot\":\n",
    "                    default_plot_params={}\n",
    "                    irrelevant_plot_keys={\"bottom\", \"cmap\", \"align\"}\n",
    "                    axe.plot(data[\"x\"], data[\"y\"],\n",
    "                             **filter_dict(metadata[\"plot_kwargs\"], \n",
    "                                           default_plot_params,\n",
    "                                          irrelevant_plot_keys)\n",
    "                            )\n",
    "                elif metadata[\"plot_type\"] == \"bar\":\n",
    "                    default_bar_params={\"snap\":False}\n",
    "                    irrelevant_bar_keys={\"cmap\",}\n",
    "                    axe.bar(data[\"x\"], data[\"y\"],\n",
    "                             **filter_dict(metadata[\"plot_kwargs\"], \n",
    "                                           default_bar_params,\n",
    "                                           irrelevant_bar_keys)\n",
    "                           )\n",
    "                elif metadata[\"plot_type\"] == \"stem\":\n",
    "                    default_stem_params={\"markerfmt\":\",\", \"basefmt\":\",\"}\n",
    "                    irrelevant_stem_keys={\"color\",\"cmap\",\"align\"}\n",
    "                    axe.stem(data[\"x\"], data[\"y\"],\n",
    "                            **filter_dict(metadata[\"plot_kwargs\"], \n",
    "                                           default_stem_params,\n",
    "                                           irrelevant_stem_keys)\n",
    "                            )\n",
    "                elif metadata[\"plot_type\"] == \"hist\":\n",
    "                    default_stem_params={}\n",
    "                    irrelevant_stem_keys={\"color\",\"cmap\",\"align\"}\n",
    "                    axe.hist(data[\"y\"],\n",
    "                             **{key: value for key,value in metadata[\"plot_kwargs\"].items() \n",
    "                                if key not in {\"cmap\"}}\n",
    "                            )\n",
    "                \n",
    "    \n",
    "                \n",
    "                if metadata[\"do_legend\"]:\n",
    "                    # custom legend\n",
    "                    if metadata[\"do_mean\"]:\n",
    "                        axe.plot([], [], marker='.', color='red',\n",
    "                                 label=dist_label_mean(data[\"mean\"]))\n",
    "                    if metadata[\"do_std\"]:\n",
    "                        axe.plot([], [], marker='.', color='red',\n",
    "                                 label=dist_label_std(data[\"std\"]))\n",
    "                    if metadata[\"do_skew\"]:\n",
    "                        axe.plot([], [], marker='.', color='red',\n",
    "                                 label=r'skew $' fr' = {data[\"skew\"]:.2f}$')\n",
    "                    if metadata[\"do_kurtosis\"]:\n",
    "                        axe.plot([], [], marker='.', color='red',\n",
    "                                 label=r'kurtosis $' fr' = {data[\"kurtosis\"]:.2f}$')\n",
    "    \n",
    "                                 \n",
    "                if metadata[\"do_title\"]:\n",
    "                    if metadata[\"do_title_name\"]:\n",
    "                        axe.set_title(f' f={data[\"f\"]}, w={data[\"w\"]}: {metadata[\"data_type\"]}')\n",
    "                    else:\n",
    "                        axe.set_title(f' f={data[\"f\"]}, w={data[\"w\"]}')\n",
    "                # axe.set_aspect('equal', 'box')\n",
    "    \n",
    "                if metadata[\"do_legend\"]:\n",
    "                    axe.legend(numpoints=1, handlelength=0,\n",
    "                               markerscale=0, handletextpad=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0720a39-e58d-4187-a17f-abf35cdc63af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560884d99eab4c0e94a7f3b630878099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-4448d3efd51a>:193: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%matplotlib widget\n",
    "\"\"\"Do main function.\n",
    "\n",
    "does the thing\n",
    "\"\"\"\n",
    "main_loc = (r'/mnt/c/Users/yoavr/Desktop'\n",
    "            r'/paraview_pipeline/hello_chemfarm'\n",
    "            r'/FW_block_aggregated/timesteps'\n",
    "            #r'/13_from_various_stability/4_from_pearling' # goes to 300, 4x4\n",
    "            #r'/HIV_gag/2_attempt_2'\n",
    "            #r'/HIV_gag/4_lines' # goes to 150\n",
    "            #r'/HIV_gag/3_fixed' # 5x5, FW_block equivalent [2,6|5,9]\n",
    "            #r'/bicurvatures/1_characterize'\n",
    "            #r'/chemfarm_example'\n",
    "           )\n",
    "metadata={}\n",
    "metadata[\"data_type\"]= \"cluster_size_dist\" # lambda1,lambda2,lamdba3, Area, Volume, mean_cluster_size, asphericity, gyration_radius, acylindricity, cluster_size_dist\n",
    "metadata[\"slice\"]=slice(-50,None,None)\n",
    "metadata[\"folder\"]=main_loc\n",
    "metadata[\"do_mean\"]=True\n",
    "metadata[\"do_std\"]=True\n",
    "metadata[\"do_skew\"] = False\n",
    "metadata[\"do_kurtosis\"] = False\n",
    "metadata[\"file_fs\"] = [0,1,2,3,5,6,7]\n",
    "metadata[\"file_ws\"] = [0,1,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "metadata[\"file_r\"] = None\n",
    "metadata[\"axe_share\"] = (True, True) # sharex, sharey\n",
    "metadata[\"order\"] = \"ij=wf\" # ij=fw ij=wf xy=fw xy=wf\n",
    "metadata[\"do_legend\"] = True\n",
    "metadata[\"do_title\"] = True\n",
    "metadata[\"do_title_name\"] = False\n",
    "metadata[\"plot_type\"] = \"bar\" # pcolor*, plot, bar, hist, stem\n",
    "metadata[\"axe_scale\"] = \"linear\", \"log\" #xy:  \"linear\", \"log\", \"symlog\", \"logit\"\n",
    "metadata[\"plot_kwargs\"] = {\"bottom\": 0, \"color\": 'red', \"cmap\":cm.plasma, \"align\":'center'}\n",
    "metadata[\"data_transform\"] = None # lambda x: x*(x<600)+600*(x>600)\n",
    "metadata[\"fig_size\"] = [6,6] # [10,6.8] # [20,18] 4_lines: worked with [40, 6.8]\n",
    "\n",
    "datas = data_from_files(metadata)\n",
    "plot_fxw(datas, metadata)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480d0ba-4890-4f59-b546-401968597ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfc574a0-1cad-41d6-ab91-9d687cac8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "\n",
    "fig.savefig('FW_aggregate_giant_dist.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910caa82-e807-4305-9525-8abc6755b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b1e154b-d44e-471d-bfc9-7a6a5c11b85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True, 'e': IndexError('list index out of range')}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b3d1b-6147-467b-8d95-a21dbc2d83f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94fe3229-de8e-4e9f-9f7b-1b4ae6541d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(r'/mnt/c/Users/yoavr/Desktop'\n",
    "            r'/paraview_pipeline/hello_chemfarm'\n",
    "            r'/FW_block_aggregated/timesteps/f3w9/' 'histogram*.csv')\n",
    "slc = slice(-20,-1)\n",
    "max_cluster = 450\n",
    "hist = np.zeros([450,2], dtype=int)\n",
    "hist[:,0] = np.arange(1,451)\n",
    "for file in file_list[slc]:\n",
    "    a = np.genfromtxt(file,\n",
    "                      skip_header=1,\n",
    "                      delimiter=',',\n",
    "                      dtype=int)\n",
    "    hist[a[...,0]-1,1] += a[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cf7c4ed-f8b6-41c3-989a-8dc5d53d6062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_vtu = glob.glob(r'/mnt/c/Users/yoavr/Desktop'\n",
    "            r'/paraview_pipeline/hello_chemfarm'\n",
    "            r'/FW_block_aggregated/timesteps/f3w9/' '*vtu')\n",
    "tree = ET.parse(timestep_vtu[-1])\n",
    "root = tree.getroot()\n",
    "node = root.findall('.//*[@Name=\"type\"]')\n",
    "c_node = root.findall('.//*[@Name=\"spontaneous_curvature\"]')[0]\n",
    "num_vertex = sum(float(x)>0 for x in c_node.text.strip().split())\n",
    "num_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6919e353-d965-41b1-8a73-700dbb91d687",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ea977f8c8e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrue_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_regex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrue_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_regex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "with open(r'/mnt/c/Users/yoavr/Desktop'\n",
    "            r'/paraview_pipeline/hello_chemfarm'\n",
    "            r'/bicurvatures/1_characterize/f1w1' '/simulation_parameters',\"r\") as file:\n",
    "        text = file.read()\n",
    "        \n",
    "text\n",
    "f_regex = re.compile(r\"(f=[\\d.]+)\")\n",
    "w_regex = re.compile(r\"(w=[\\d.]+)\")\n",
    "true_f = re.findall(f_regex, text)[0]\n",
    "true_w = re.findall(w_regex, text)[0]\n",
    "data[\"f\"] = float(true_f[2:])\n",
    "data[\"w\"] = float(true_w[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c07ca58-b567-40c9-bdce-9960a19893e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f=0.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c74f01c7-b0c3-41ce-8066-6bf989688d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>number_of_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster_size  number_of_clusters\n",
       "0               1                   1\n",
       "1               2                   0\n",
       "2               3                   0\n",
       "3               4                   0\n",
       "4               5                   0\n",
       "..            ...                 ...\n",
       "445           446                   0\n",
       "446           447                   0\n",
       "447           448                   0\n",
       "448           449                   1\n",
       "449           450                  18\n",
       "\n",
       "[450 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"cluster_size\":hist[:,0], \"number_of_clusters\":hist[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e3e405e-2d95-48bf-89e0-639897d6bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a={\"hi\":1,\"bye\":2}\n",
    "b={\"hi\":3,\"hey\":4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ebafc9d-1ad1-4f7e-8bc2-1155122ad87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bye', 'hey', 'hi'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys() | b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb482aa6-37f8-4538-a161-809a036438fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for key in a.keys() | b.keys():\n",
    "    print(a[key]) if key in a else print(b[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a69eb628-b564-4bd5-9dd3-933265c0db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(given_dict, default_dict, relevant_keys_set):\n",
    "        \"filter a given dectionary to only include keys in the relevant_keys set, then add defaults\"\n",
    "        relevant_given = {key: value for key, value in given_dict.items() if key in relevant_keys_set}\n",
    "        for key in default_dict.keys():\n",
    "            if key not in relevant_given:\n",
    "                relevant_given[key]=default_dict[key]\n",
    "        return relevant_given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb9698d2-e064-4e96-8ffe-31aa423c5284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': 3, 'bye': 2}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dict(b,a,{\"bye\",\"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9eacb4d1-604c-48e2-84ca-a8969be46ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'banana'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-4234cba76801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"banana\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'banana'"
     ]
    }
   ],
   "source": [
    "a[\"banana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074f76a-f90c-4412-b34b-44ad87765ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6826ef38-a67d-4781-b272-e166be6ab91b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/opt/workspace/thing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-297d476b0127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/opt/workspace/thing.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/opt/workspace/thing.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('/opt/workspace/thing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af4f30-f239-4a69-893d-00ef4905e90f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
